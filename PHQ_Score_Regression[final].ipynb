{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91SVeHnHQAPo"
      },
      "outputs": [],
      "source": [
        "#Install missing dependencies\n",
        "\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "22uAUPmsvrW2"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "import numpy as np\n",
        "import glob\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Input, Activation, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import compute_sample_weight\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4zHUAYbaGTxQ"
      },
      "outputs": [],
      "source": [
        "#Read data labels\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/AVEC_Challenge_Packed/labels/train_split.csv')\n",
        "dev = pd.read_csv('/content/drive/MyDrive/AVEC_Challenge_Packed/labels/dev_split.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9EychExPGlhe"
      },
      "outputs": [],
      "source": [
        "#Create training label variables\n",
        "\n",
        "train_ids = train.Participant_ID\n",
        "train_targets = train.PHQ_Score\n",
        "train_binary = train.PHQ_Binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xkVUCOidHFWG"
      },
      "outputs": [],
      "source": [
        "#Create validation label variables\n",
        "\n",
        "dev_ids = dev.Participant_ID\n",
        "dev_targets = dev.PHQ_Score\n",
        "dev_binary = dev.PHQ_Binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uYwnq10YSiwK"
      },
      "outputs": [],
      "source": [
        "#Read training audio files and transcripts\n",
        "\n",
        "train_audio = sorted(glob.glob('/content/drive/MyDrive/avec/train/*.wav'))\n",
        "train_transcripts = sorted(glob.glob('/content/drive/MyDrive/avec/train/*.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VpG75q-CTW6n"
      },
      "outputs": [],
      "source": [
        "#Read validation audio files and transcripts\n",
        "\n",
        "dev_audio = sorted(glob.glob('/content/drive/MyDrive/avec/dev/*.wav'))\n",
        "dev_transcripts = sorted(glob.glob('/content/drive/MyDrive/avec/dev/*.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3plnLfqCbJDk"
      },
      "outputs": [],
      "source": [
        "def audio_feature_extraction(audio_file, transcript_file):\n",
        "  \"\"\"\n",
        "  Preprocesses and creates mel-spectrograms from audio data\n",
        "  \"\"\"\n",
        "\n",
        "  transcript = pd.read_csv(transcript_file)\n",
        "  timestamps = []\n",
        "\n",
        "  #Get timestamps for patient responses\n",
        "  for tup in transcript.loc[:, ['Start_Time', 'End_Time']].itertuples(False, name=None):\n",
        "    timestamps.append(tup)\n",
        "\n",
        "  #Read audio data\n",
        "  audio = AudioSegment.from_wav(audio_file)\n",
        "\n",
        "  #New audio for patient responses\n",
        "  newAudio = audio[0:0]\n",
        "\n",
        "  #Patient audio segmentation\n",
        "  for idx in range(len(timestamps)-1):\n",
        "    #Extract and append patient responses to new audio\n",
        "    t1 = timestamps[idx][0] * 1000\n",
        "    t2 = timestamps[idx][1] * 1000\n",
        "    oldAudio = audio[t1:t2]\n",
        "    newAudio = newAudio + oldAudio\n",
        "\n",
        "  #Split audio data into 15s audio slices\n",
        "  audio_chunks = make_chunks(newAudio, 15000)\n",
        "  features = []\n",
        "\n",
        "  #Create mel-spectrogram features from each audio slices\n",
        "  for chunk in audio_chunks[:-1]:\n",
        "    spectrogram = librosa.stft(np.array(chunk.get_array_of_samples(), dtype='float64'))\n",
        "\n",
        "    spectrogram_magnitude, phase = librosa.magphase(spectrogram)\n",
        "    mel_scale = librosa.feature.melspectrogram(S=spectrogram_magnitude, sr=chunk.frame_rate, n_mels=80)\n",
        "\n",
        "    mel_spectrogram = librosa.amplitude_to_db(mel_scale, ref=np.min)\n",
        "    \n",
        "    features.append(mel_spectrogram)\n",
        "\n",
        "  return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RqFSN_5DKEtP"
      },
      "outputs": [],
      "source": [
        "train_features = []\n",
        "dev_features = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BildUcOeJnyz"
      },
      "outputs": [],
      "source": [
        "#Create training features\n",
        "\n",
        "for audio_file, transcript_file in zip(train_audio, train_transcripts):\n",
        "  features = audio_feature_extraction(audio_file, transcript_file)\n",
        "  features = np.asarray(features).astype('float64')\n",
        "  train_features.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4T1W1icIJyyP"
      },
      "outputs": [],
      "source": [
        "#Create validation features\n",
        "\n",
        "for audio_file, transcript_file in zip(dev_audio, dev_transcripts):\n",
        "  features = audio_feature_extraction(audio_file, transcript_file)\n",
        "  features = np.asarray(features).astype('float64')\n",
        "  dev_features.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4bxdY1tcgk3b"
      },
      "outputs": [],
      "source": [
        "#Map participant ids to features and targets\n",
        "\n",
        "train_feature_id_map = dict(zip(train_ids, train_features))\n",
        "dev_feature_id_map = dict(zip(dev_ids, dev_features))\n",
        "\n",
        "train_target_id_map = dict(zip(train_ids, train_targets))\n",
        "dev_target_id_map = dict(zip(dev_ids, dev_targets))\n",
        "\n",
        "train_binary_id_map = dict(zip(train_ids, train_binary))\n",
        "dev_binary_id_map = dict(zip(dev_ids, dev_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fe-PtalV5BNa"
      },
      "outputs": [],
      "source": [
        "#Get features that match the required shape\n",
        "\n",
        "train_features_ = [feature for feature in train_features if feature.shape[2] == 469]\n",
        "dev_features_ = [feature for feature in dev_features if feature.shape[2] == 469]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FSEtl6gckHVj"
      },
      "outputs": [],
      "source": [
        "#Create new target variables\n",
        "\n",
        "train_targets_ = pd.Series(dtype='int64')\n",
        "dev_targets_ = pd.Series(dtype='int64')\n",
        "\n",
        "train_binary_ = pd.Series(dtype='int64')\n",
        "dev_binary_ = pd.Series(dtype='int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3i_ReosIh8nQ"
      },
      "outputs": [],
      "source": [
        "#Assign new training target variables to account for audio slices\n",
        "\n",
        "for id, feature in train_feature_id_map.items():\n",
        "  if feature.shape[2] == 469:\n",
        "    train_targets_ = train_targets_.append(pd.Series([train_target_id_map[id]]*feature.shape[0]), ignore_index=True)\n",
        "    train_binary_ = train_binary_.append(pd.Series([train_binary_id_map[id]]*feature.shape[0]), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "woV1goKprUq7"
      },
      "outputs": [],
      "source": [
        "#Assign new validation target variables to account for audio slices\n",
        "\n",
        "for id, feature in dev_feature_id_map.items():\n",
        "  if feature.shape[2] == 469:\n",
        "    dev_targets_ = dev_targets_.append(pd.Series([dev_target_id_map[id]]*feature.shape[0]), ignore_index=True)\n",
        "    dev_binary_ = dev_binary_.append(pd.Series([dev_binary_id_map[id]]*feature.shape[0]), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mA8J1Nnd5mWU"
      },
      "outputs": [],
      "source": [
        "#Assign new feature variables to account for audio slices\n",
        "\n",
        "train_features_ = np.concatenate(train_features_)\n",
        "dev_features_ = np.concatenate(dev_features_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyH1cm-4ribs"
      },
      "outputs": [],
      "source": [
        "#Check shape consistency\n",
        "\n",
        "print(train_features_.shape)\n",
        "print(train_targets_.shape)\n",
        "print(train_binary_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtgPypnBrtRW"
      },
      "outputs": [],
      "source": [
        "print(dev_features_.shape)\n",
        "print(dev_targets_.shape)\n",
        "print(dev_binary_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zj42j81367mY"
      },
      "outputs": [],
      "source": [
        "def resample(features, targets, binary):\n",
        "  \"\"\"\n",
        "  Oversamples the minority class to create a balanced dataset\n",
        "  \"\"\"\n",
        "  sm = SMOTE(random_state=42)\n",
        "\n",
        "  features_ = np.reshape(features, \n",
        "                         (features.shape[0], features.shape[1]*features.shape[2]))\n",
        "  targets_ = np.array(targets).reshape(-1, 1)\n",
        "  binary_ = np.array(binary).reshape(-1, 1)\n",
        "\n",
        "  features_res, y = sm.fit_resample(features_, binary_)\n",
        "  targets_res, y = sm.fit_resample(targets_, binary_)\n",
        "\n",
        "  features_res = np.reshape(features_res,\n",
        "                            (features_res.shape[0], features.shape[1], features.shape[2]))\n",
        "  target_res = np.squeeze(targets_res)\n",
        "\n",
        "  return features_res, target_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HmzXVSQ752d8"
      },
      "outputs": [],
      "source": [
        "#Resample training features and targets\n",
        "\n",
        "train_features_, train_targets_ = resample(train_features_, train_targets_, train_binary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfbFYDn0zheX"
      },
      "outputs": [],
      "source": [
        "#Check shape consistency\n",
        "\n",
        "print(train_features_.shape)\n",
        "print(train_targets_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EFpLIwy_vw-i"
      },
      "outputs": [],
      "source": [
        "#Perform min-max normalization\n",
        "\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7RVFp3Io6KeR"
      },
      "outputs": [],
      "source": [
        "X_train = train_features_\n",
        "\n",
        "for sample in range(X_train.shape[0]):\n",
        "  X_train[sample] = scaler.fit_transform(X_train[sample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8ithtY6v6liS"
      },
      "outputs": [],
      "source": [
        "X_test = dev_features_\n",
        "\n",
        "for sample in range(X_test.shape[0]):\n",
        "  X_test[sample] = scaler.transform(X_test[sample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VQqHlFDpLLpn"
      },
      "outputs": [],
      "source": [
        "#Save the sacler\n",
        "\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GaQbi2F428KU"
      },
      "outputs": [],
      "source": [
        "y_train = train_targets_\n",
        "y_test = dev_targets_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8t8tenAw7kIR"
      },
      "outputs": [],
      "source": [
        "#Get sample weights\n",
        "\n",
        "train_weights = compute_sample_weight('balanced', train_targets_)\n",
        "test_weights = compute_sample_weight('balanced', dev_targets_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3e_olI4XtIwM"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  \"\"\"\n",
        "  Returns a one-dimensional convolution neural network for a regression task\n",
        "  \"\"\"\n",
        "  inputs = Input(shape=(80,469,1))\n",
        "\n",
        "  x = Conv2D(32, (1,7))(inputs)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling2D((4,3), (1,3))(x)\n",
        "  x = Conv2D(32, (1,7), 2)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling2D((1,3), (1,3))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(128)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Dense(128)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, decay=0.0001),\n",
        "                loss='huber',\n",
        "                metrics=['mae'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GvKtCz2gufkN"
      },
      "outputs": [],
      "source": [
        "#Create model\n",
        "\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NQ7jE0asByrH"
      },
      "outputs": [],
      "source": [
        "#Callback to prevent overfitting\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_mae', \n",
        "                                            patience=10, \n",
        "                                            mode='min', \n",
        "                                            restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QOq3O-N5_70"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "\n",
        "model_history = model.fit(x=X_train, \n",
        "                          y=y_train, \n",
        "                          batch_size=4, \n",
        "                          epochs=30, \n",
        "                          validation_data=(X_test, y_test, test_weights),\n",
        "                          sample_weight=train_weights, \n",
        "                          callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(name, title):\n",
        "  '''\n",
        "  Plots model metrics\n",
        "  '''\n",
        "  plt.plot(model_history.history[name], color='blue', label=name)\n",
        "  plt.plot(model_history.history['val_'+name], color='green', label='val_'+name)\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel(name)\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9vp5VnmelLz3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot model metrics\n",
        "\n",
        "plot_metric('loss', 'Training loss vs. Validation loss')\n",
        "plot_metric('mae', 'Training mae vs. Validation mae')"
      ],
      "metadata": {
        "id": "kW3WVTFIlM43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "HA0g9TCTH2Iv"
      },
      "outputs": [],
      "source": [
        "#model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JHjJU11mshZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PHQ_Score_Regression[final].ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}